{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "import keras\n",
    "# from mode.config import *\n",
    "from tensorflow.python.keras.optimizers import TFOptimizer\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from matplotlib import pyplot as plt\n",
    "from tf_keras_vis.activation_maximization import ActivationMaximization\n",
    "from tf_keras_vis.activation_maximization.callbacks import Progress\n",
    "from tf_keras_vis.activation_maximization.input_modifiers import Jitter, Rotate2D\n",
    "from tf_keras_vis.activation_maximization.regularizers import TotalVariation2D, Norm\n",
    "from tf_keras_vis.utils.model_modifiers import ExtractIntermediateLayer, ReplaceToLinear\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "with open('train.pickle', 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "#Convert to np.array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X=X[:100, :,:]\n",
    "y=y[:100, :,:]\n",
    "y = tf.keras.utils.to_categorical(y, 6)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, 6)\n",
    "# y_test = tf.keras.utils.to_categorical(y_test, 6)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "X=X_test[:1, :,:]\n",
    "X.shape\n",
    "X=np.moveaxis(X, 0, -1)\n",
    "X.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(512, 512, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# smooth = 1.\n",
    "\n",
    "# def dice_coef(y_true, y_pred):\n",
    "#     y_true_f = K.flatten(y_true)\n",
    "#     y_pred_f = K.flatten(y_pred)\n",
    "#     intersection = K.sum(y_true_f * y_pred_f)\n",
    "#     return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "# def dice_loss(y_true, y_pred):\n",
    "#   y_true = tf.cast(y_true, tf.float32)\n",
    "#   y_pred = tf.math.softmax(y_pred)\n",
    "#   numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "#   denominator = tf.reduce_sum(y_true + y_pred)\n",
    "\n",
    "#   return 1 - numerator / denominator\n",
    "\n",
    "# path_to_model = '/Users/salvatoreesposito/Desktop/AttXnet_1/'\n",
    "# model = tf.keras.models.load_model(path_to_model, custom_objects={'dice_loss':dice_loss, \"dice_coef\":dice_coef})\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from keras_unet_collection import models, utils\n",
    "\n",
    "model = models.att_unet_2d((512, 512, 1), filter_num=[64, 128, 256, 512, 1024], n_labels=6, \n",
    "                           stack_num_down=2, stack_num_up=2, activation='ReLU', \n",
    "                           atten_activation='ReLU', attention='add', output_activation='Sigmoid', \n",
    "                           batch_norm=True, pool=False, unpool=False, \n",
    "                           backbone=None, weights='imagenet', \n",
    "                           freeze_backbone=True, freeze_batch_norm=True, \n",
    "                           name='attunet')\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "print(model.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"attunet_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down0_0 (Conv2D)        (None, 512, 512, 64) 576         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down0_0_bn (BatchNormal (None, 512, 512, 64) 256         attunet_down0_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down0_0_activation (ReL (None, 512, 512, 64) 0           attunet_down0_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down0_1 (Conv2D)        (None, 512, 512, 64) 36864       attunet_down0_0_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down0_1_bn (BatchNormal (None, 512, 512, 64) 256         attunet_down0_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down0_1_activation (ReL (None, 512, 512, 64) 0           attunet_down0_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down1_encode_stride_con (None, 256, 256, 128 32768       attunet_down0_1_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down1_encode_bn (BatchN (None, 256, 256, 128 512         attunet_down1_encode_stride_conv[\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down1_encode_activation (None, 256, 256, 128 0           attunet_down1_encode_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down1_conv_0 (Conv2D)   (None, 256, 256, 128 147456      attunet_down1_encode_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down1_conv_0_bn (BatchN (None, 256, 256, 128 512         attunet_down1_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down1_conv_0_activation (None, 256, 256, 128 0           attunet_down1_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down1_conv_1 (Conv2D)   (None, 256, 256, 128 147456      attunet_down1_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down1_conv_1_bn (BatchN (None, 256, 256, 128 512         attunet_down1_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down1_conv_1_activation (None, 256, 256, 128 0           attunet_down1_conv_1_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down2_encode_stride_con (None, 128, 128, 256 131072      attunet_down1_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down2_encode_bn (BatchN (None, 128, 128, 256 1024        attunet_down2_encode_stride_conv[\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down2_encode_activation (None, 128, 128, 256 0           attunet_down2_encode_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down2_conv_0 (Conv2D)   (None, 128, 128, 256 589824      attunet_down2_encode_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down2_conv_0_bn (BatchN (None, 128, 128, 256 1024        attunet_down2_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down2_conv_0_activation (None, 128, 128, 256 0           attunet_down2_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down2_conv_1 (Conv2D)   (None, 128, 128, 256 589824      attunet_down2_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down2_conv_1_bn (BatchN (None, 128, 128, 256 1024        attunet_down2_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down2_conv_1_activation (None, 128, 128, 256 0           attunet_down2_conv_1_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down3_encode_stride_con (None, 64, 64, 512)  524288      attunet_down2_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down3_encode_bn (BatchN (None, 64, 64, 512)  2048        attunet_down3_encode_stride_conv[\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down3_encode_activation (None, 64, 64, 512)  0           attunet_down3_encode_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down3_conv_0 (Conv2D)   (None, 64, 64, 512)  2359296     attunet_down3_encode_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down3_conv_0_bn (BatchN (None, 64, 64, 512)  2048        attunet_down3_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down3_conv_0_activation (None, 64, 64, 512)  0           attunet_down3_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down3_conv_1 (Conv2D)   (None, 64, 64, 512)  2359296     attunet_down3_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down3_conv_1_bn (BatchN (None, 64, 64, 512)  2048        attunet_down3_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down3_conv_1_activation (None, 64, 64, 512)  0           attunet_down3_conv_1_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down4_encode_stride_con (None, 32, 32, 1024) 2097152     attunet_down3_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down4_encode_bn (BatchN (None, 32, 32, 1024) 4096        attunet_down4_encode_stride_conv[\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down4_encode_activation (None, 32, 32, 1024) 0           attunet_down4_encode_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down4_conv_0 (Conv2D)   (None, 32, 32, 1024) 9437184     attunet_down4_encode_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down4_conv_0_bn (BatchN (None, 32, 32, 1024) 4096        attunet_down4_conv_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down4_conv_0_activation (None, 32, 32, 1024) 0           attunet_down4_conv_0_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down4_conv_1 (Conv2D)   (None, 32, 32, 1024) 9437184     attunet_down4_conv_0_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_down4_conv_1_bn (BatchN (None, 32, 32, 1024) 4096        attunet_down4_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_down4_conv_1_activation (None, 32, 32, 1024) 0           attunet_down4_conv_1_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_trans_conv ( (None, 64, 64, 512)  4719104     attunet_down4_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_bn (BatchNor (None, 64, 64, 512)  2048        attunet_up0_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_activation ( (None, 64, 64, 512)  0           attunet_up0_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_theta_x (Conv2D (None, 64, 64, 256)  131328      attunet_down3_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_phi_g (Conv2D)  (None, 64, 64, 256)  131328      attunet_up0_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_add (Add)       (None, 64, 64, 256)  0           attunet_up0_att_theta_x[0][0]    \n",
      "                                                                 attunet_up0_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_activation (ReL (None, 64, 64, 256)  0           attunet_up0_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_psi_f (Conv2D)  (None, 64, 64, 1)    257         attunet_up0_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_sigmoid (Activa (None, 64, 64, 1)    0           attunet_up0_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_masking (Multip (None, 64, 64, 512)  0           attunet_down3_conv_1_activation[0\n",
      "                                                                 attunet_up0_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_concat (Concatenate (None, 64, 64, 1024) 0           attunet_up0_decode_activation[0][\n",
      "                                                                 attunet_up0_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 64, 64, 512)  4718592     attunet_up0_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 64, 64, 512)  2048        attunet_up0_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 64, 64, 512)  0           attunet_up0_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 64, 64, 512)  2359296     attunet_up0_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 64, 64, 512)  2048        attunet_up0_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 64, 64, 512)  0           attunet_up0_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_trans_conv ( (None, 128, 128, 256 1179904     attunet_up0_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_bn (BatchNor (None, 128, 128, 256 1024        attunet_up1_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_activation ( (None, 128, 128, 256 0           attunet_up1_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_theta_x (Conv2D (None, 128, 128, 128 32896       attunet_down2_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_phi_g (Conv2D)  (None, 128, 128, 128 32896       attunet_up1_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_add (Add)       (None, 128, 128, 128 0           attunet_up1_att_theta_x[0][0]    \n",
      "                                                                 attunet_up1_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_activation (ReL (None, 128, 128, 128 0           attunet_up1_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_psi_f (Conv2D)  (None, 128, 128, 1)  129         attunet_up1_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_sigmoid (Activa (None, 128, 128, 1)  0           attunet_up1_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_masking (Multip (None, 128, 128, 256 0           attunet_down2_conv_1_activation[0\n",
      "                                                                 attunet_up1_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_concat (Concatenate (None, 128, 128, 512 0           attunet_up1_decode_activation[0][\n",
      "                                                                 attunet_up1_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 128, 128, 256 1179648     attunet_up1_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 128, 128, 256 1024        attunet_up1_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 128, 128, 256 0           attunet_up1_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 128, 128, 256 589824      attunet_up1_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 128, 128, 256 1024        attunet_up1_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 128, 128, 256 0           attunet_up1_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_trans_conv ( (None, 256, 256, 128 295040      attunet_up1_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_bn (BatchNor (None, 256, 256, 128 512         attunet_up2_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_activation ( (None, 256, 256, 128 0           attunet_up2_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_att_theta_x (Conv2D (None, 256, 256, 64) 8256        attunet_down1_conv_1_activation[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_att_phi_g (Conv2D)  (None, 256, 256, 64) 8256        attunet_up2_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_att_add (Add)       (None, 256, 256, 64) 0           attunet_up2_att_theta_x[0][0]    \n",
      "                                                                 attunet_up2_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_att_activation (ReL (None, 256, 256, 64) 0           attunet_up2_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_att_psi_f (Conv2D)  (None, 256, 256, 1)  65          attunet_up2_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_att_sigmoid (Activa (None, 256, 256, 1)  0           attunet_up2_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_att_masking (Multip (None, 256, 256, 128 0           attunet_down1_conv_1_activation[0\n",
      "                                                                 attunet_up2_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_concat (Concatenate (None, 256, 256, 256 0           attunet_up2_decode_activation[0][\n",
      "                                                                 attunet_up2_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 256, 256, 128 294912      attunet_up2_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 256, 256, 128 512         attunet_up2_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 256, 256, 128 0           attunet_up2_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 256, 256, 128 147456      attunet_up2_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 256, 256, 128 512         attunet_up2_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 256, 256, 128 0           attunet_up2_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_decode_trans_conv ( (None, 512, 512, 64) 73792       attunet_up2_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_decode_bn (BatchNor (None, 512, 512, 64) 256         attunet_up3_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_decode_activation ( (None, 512, 512, 64) 0           attunet_up3_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_att_theta_x (Conv2D (None, 512, 512, 32) 2080        attunet_down0_1_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_att_phi_g (Conv2D)  (None, 512, 512, 32) 2080        attunet_up3_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_att_add (Add)       (None, 512, 512, 32) 0           attunet_up3_att_theta_x[0][0]    \n",
      "                                                                 attunet_up3_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_att_activation (ReL (None, 512, 512, 32) 0           attunet_up3_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_att_psi_f (Conv2D)  (None, 512, 512, 1)  33          attunet_up3_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_att_sigmoid (Activa (None, 512, 512, 1)  0           attunet_up3_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_att_masking (Multip (None, 512, 512, 64) 0           attunet_down0_1_activation[0][0] \n",
      "                                                                 attunet_up3_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_concat (Concatenate (None, 512, 512, 128 0           attunet_up3_decode_activation[0][\n",
      "                                                                 attunet_up3_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_conv_after_concat_0 (None, 512, 512, 64) 73728       attunet_up3_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_conv_after_concat_0 (None, 512, 512, 64) 256         attunet_up3_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_conv_after_concat_0 (None, 512, 512, 64) 0           attunet_up3_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_conv_after_concat_1 (None, 512, 512, 64) 36864       attunet_up3_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_conv_after_concat_1 (None, 512, 512, 64) 256         attunet_up3_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up3_conv_after_concat_1 (None, 512, 512, 64) 0           attunet_up3_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output (Conv2D)         (None, 512, 512, 6)  390         attunet_up3_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output_activation (Acti (None, 512, 512, 6)  0           attunet_output[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 43,943,466\n",
      "Trainable params: 43,925,930\n",
      "Non-trainable params: 17,536\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def dice_coef(y_true, y_pred, const=K.epsilon()):\n",
    "    '''\n",
    "    Sørensen–Dice coefficient for 2-d samples.\n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "        y_true, y_pred: predicted outputs and targets.\n",
    "        const: a constant that smooths the loss gradient and reduces numerical instabilities.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # flatten 2-d tensors\n",
    "    y_true_pos = tf.reshape(y_true, [-1])\n",
    "    y_pred_pos = tf.reshape(y_pred, [-1])\n",
    "    \n",
    "    # get true pos (TP), false neg (FN), false pos (FP).\n",
    "    true_pos  = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.reduce_sum(y_true_pos * (1-y_pred_pos))\n",
    "    false_pos = tf.reduce_sum((1-y_true_pos) * y_pred_pos)\n",
    "    \n",
    "    # 2TP/(2TP+FP+FN) == 2TP/()\n",
    "    coef_val = (2.0 * true_pos + const)/(2.0 * true_pos + false_pos + false_neg)\n",
    "    \n",
    "    return coef_val\n",
    "\n",
    "\n",
    "\n",
    "def dice(y_true, y_pred, const=K.epsilon()):\n",
    "\n",
    "    # tf tensor casting\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "\n",
    "    # <--- squeeze-out length-1 dimensions.\n",
    "    y_pred = tf.squeeze(y_pred)\n",
    "    y_true = tf.squeeze(y_true)\n",
    "\n",
    "    loss_val = 1 - dice_coef(y_true, y_pred, const=const)\n",
    "\n",
    "    return loss_val"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "model.compile(loss=dice, optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=dice_coef)\n",
    "history=model.fit(X_train, y_train, validation_split=0.2, epochs=1, batch_size=1, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0b0301e13588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdice_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/envs/autosegmentation/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/autosegmentation/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/autosegmentation/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/autosegmentation/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/autosegmentation/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/autosegmentation/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/autosegmentation/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = model.predict([X])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ax_decorate_box(ax):\n",
    "    [j.set_linewidth(0) for j in ax.spines.values()]\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", bottom=False, top=False, \\\n",
    "               labelbottom=False, left=False, right=False, labelleft=False)\n",
    "    return ax"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "i_sample = 1\n",
    "\n",
    "fig, AX = plt.subplots(1, 3, figsize=(13, (13-0.2)/3))\n",
    "plt.subplots_adjust(0, 0, 1, 1, hspace=0, wspace=0.1)\n",
    "for ax in AX:\n",
    "    ax = ax_decorate_box(ax)\n",
    "AX[0].pcolormesh(np.mean(X[i_sample, ...,], axis=-1), cmap=plt.cm.gray)\n",
    "AX[1].pcolormesh(y_pred[i_sample, ..., 0], cmap=plt.cm.jet)\n",
    "AX[2].pcolormesh(y[i_sample, ..., 0], cmap=plt.cm.jet)\n",
    "\n",
    "AX[0].set_title(\"Original\", fontsize=14)\n",
    "AX[1].set_title(\"Pixels belong to human (red for high probabilities)\", fontsize=14)\n",
    "AX[2].set_title(\"Labeled truth\", fontsize=14)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-945cac24a9a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max_decorate_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mAX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpcolormesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mAX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpcolormesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mAX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpcolormesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 936x307.2 with 3 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"321.6pt\" version=\"1.1\" viewBox=\"0 0 950.4 321.6\" width=\"950.4pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-08-19T19:24:46.261873</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 321.6 \nL 950.4 321.6 \nL 950.4 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 7.2 314.4 \nL 299.7 314.4 \nL 299.7 7.2 \nL 7.2 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\"/>\n    <g id=\"xtick_2\"/>\n    <g id=\"xtick_3\"/>\n    <g id=\"xtick_4\"/>\n    <g id=\"xtick_5\"/>\n    <g id=\"xtick_6\"/>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\"/>\n    <g id=\"ytick_2\"/>\n    <g id=\"ytick_3\"/>\n    <g id=\"ytick_4\"/>\n    <g id=\"ytick_5\"/>\n    <g id=\"ytick_6\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 7.2 314.4 \nL 7.2 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 299.7 314.4 \nL 299.7 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 7.2 314.4 \nL 299.7 314.4 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 7.2 7.2 \nL 299.7 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 328.95 314.4 \nL 621.45 314.4 \nL 621.45 7.2 \nL 328.95 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_7\"/>\n    <g id=\"xtick_8\"/>\n    <g id=\"xtick_9\"/>\n    <g id=\"xtick_10\"/>\n    <g id=\"xtick_11\"/>\n    <g id=\"xtick_12\"/>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_7\"/>\n    <g id=\"ytick_8\"/>\n    <g id=\"ytick_9\"/>\n    <g id=\"ytick_10\"/>\n    <g id=\"ytick_11\"/>\n    <g id=\"ytick_12\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 328.95 314.4 \nL 328.95 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 621.45 314.4 \nL 621.45 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 328.95 314.4 \nL 621.45 314.4 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 328.95 7.2 \nL 621.45 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_12\">\n    <path d=\"M 650.7 314.4 \nL 943.2 314.4 \nL 943.2 7.2 \nL 650.7 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_5\">\n    <g id=\"xtick_13\"/>\n    <g id=\"xtick_14\"/>\n    <g id=\"xtick_15\"/>\n    <g id=\"xtick_16\"/>\n    <g id=\"xtick_17\"/>\n    <g id=\"xtick_18\"/>\n   </g>\n   <g id=\"matplotlib.axis_6\">\n    <g id=\"ytick_13\"/>\n    <g id=\"ytick_14\"/>\n    <g id=\"ytick_15\"/>\n    <g id=\"ytick_16\"/>\n    <g id=\"ytick_17\"/>\n    <g id=\"ytick_18\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 650.7 314.4 \nL 650.7 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 943.2 314.4 \nL 943.2 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 650.7 314.4 \nL 943.2 314.4 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 650.7 7.2 \nL 943.2 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n  </g>\n </g>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('autosegmentation': conda)"
  },
  "interpreter": {
   "hash": "125bec86af28abc83cf35ecc07aed6c1f98608cb92e6f2b8d1d63cbdf2bcb29e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}